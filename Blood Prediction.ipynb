{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Blood transfusions are a critical component of healthcare, often serving as a life-saving intervention in situations such as major surgeries, severe injuries, and the treatment of numerous medical conditions including anemia and cancer. Maintaining a steady supply of blood is vital for healthcare systems worldwide, yet ensuring an adequate and timely supply is a persistent challenge. According to the American Red Cross, every two seconds someone in the United States needs blood, underscoring the constant demand for donations.\n",
    "\n",
    "Our dataset comes from a mobile blood donation unit in Taiwan. This unit visits various universities to conduct blood drives, aiming to collect enough donations to meet the ongoing need. Predicting donor behavior, specifically whether a donor will give blood the next time the mobile unit visits, is crucial for optimizing these blood drives.\n",
    "\n",
    "The dataset is called transfusion and utilizes the RFMTC marketing model, which is a variation of the traditional RFM (Recency, Frequency, Monetary) model. We will explore this model and how it applies to blood donation behavior in this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 and 2: Load the Dataset\n",
    "In this section, we import necessary libraries and load the dataset containing blood donation records. We display the first few rows of the dataset to get an initial look at the structure and contents of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
      "0                 2                 50                  12500             98   \n",
      "1                 0                 13                   3250             28   \n",
      "2                 1                 16                   4000             35   \n",
      "3                 2                 20                   5000             45   \n",
      "4                 1                 24                   6000             77   \n",
      "\n",
      "   whether he/she donated blood in March 2007  \n",
      "0                                           1  \n",
      "1                                           1  \n",
      "2                                           1  \n",
      "3                                           1  \n",
      "4                                           0  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and load the dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset and display the first few rows\n",
    "transfusion = pd.read_csv('transfusion.csv')\n",
    "print(transfusion.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Dataset Information\n",
    "Here, we display general information about the dataset, including the number of entries, the columns present, and their data types. This helps us understand the data's structure and check for any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 748 entries, 0 to 747\n",
      "Data columns (total 5 columns):\n",
      " #   Column                                      Non-Null Count  Dtype\n",
      "---  ------                                      --------------  -----\n",
      " 0   Recency (months)                            748 non-null    int64\n",
      " 1   Frequency (times)                           748 non-null    int64\n",
      " 2   Monetary (c.c. blood)                       748 non-null    int64\n",
      " 3   Time (months)                               748 non-null    int64\n",
      " 4   whether he/she donated blood in March 2007  748 non-null    int64\n",
      "dtypes: int64(5)\n",
      "memory usage: 29.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Get information about the dataset\n",
    "print(transfusion.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Rename the Target Column\n",
    "We rename the target column to 'target' for simplicity. This makes it easier to reference this column in subsequent steps. We then display the first two rows to confirm the change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)  \\\n",
      "0                 2                 50                  12500             98   \n",
      "1                 0                 13                   3250             28   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n"
     ]
    }
   ],
   "source": [
    "# Rename the target column for simplicity\n",
    "transfusion.rename(columns={'whether he/she donated blood in March 2007': 'target'}, inplace=True)\n",
    "print(transfusion.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Value Counts of the Target Column\n",
    "This section provides the distribution of the target variable to understand the balance between the classes (donated or not). We look at both the count and the proportion of each class to gauge if the dataset is imbalanced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    570\n",
      "1    178\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    0.762032\n",
      "1    0.237968\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Display the value counts of the target column\n",
    "print(transfusion['target'].value_counts())\n",
    "print(transfusion['target'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6: Split the Dataset\n",
    "We split the dataset into training and testing sets. The split ensures that we have separate data for training the model and evaluating its performance. Stratification is used to maintain the distribution of the target variable in both sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Recency (months)  Frequency (times)  Monetary (c.c. blood)  Time (months)\n",
      "285                11                  2                    500             14\n",
      "731                14                  3                    750             79\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    transfusion.drop(columns='target'),\n",
    "    transfusion.target,\n",
    "    test_size=0.2,\n",
    "    stratify=transfusion.target\n",
    ")\n",
    "print(X_train.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7: Model Selection with TPOT\n",
    "We use TPOT, an automated machine learning tool, to find the best model for predicting blood donation. TPOT tests multiple models and parameters, selecting the one with the highest internal cross-validation score. The model's performance is evaluated using the AUC score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                             \n",
      "Generation 1 - Current best internal CV score: 0.7528179787657192\n",
      "                                                                             \n",
      "Generation 2 - Current best internal CV score: 0.7528179787657192\n",
      "                                                                             \n",
      "Generation 3 - Current best internal CV score: 0.7528179787657192\n",
      "                                                                             \n",
      "Generation 4 - Current best internal CV score: 0.7528179787657192\n",
      "                                                                              \n",
      "Generation 5 - Current best internal CV score: 0.7581001591041214\n",
      "                                                                              \n",
      "Best pipeline: LogisticRegression(ZeroCount(MinMaxScaler(input_matrix)), C=25.0, dual=False, penalty=l2)\n",
      "\n",
      "AUC score: 0.7745\n",
      "\n",
      "Best pipeline steps:\n",
      "1. MinMaxScaler()\n",
      "2. ZeroCount()\n",
      "3. LogisticRegression(C=25.0, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "# Use TPOT to find the best model\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "tpot = TPOTClassifier(\n",
    "    generations=5,\n",
    "    population_size=20,\n",
    "    verbosity=2,\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    disable_update_check=True,\n",
    "    config_dict='TPOT light'\n",
    ")\n",
    "tpot.fit(X_train, y_train)\n",
    "tpot_auc_score = roc_auc_score(y_test, tpot.predict_proba(X_test)[:, 1])\n",
    "print(f'\\nAUC score: {tpot_auc_score:.4f}')\n",
    "print('\\nBest pipeline steps:', end='\\n')\n",
    "for idx, (name, transform) in enumerate(tpot.fitted_pipeline_.steps, start=1):\n",
    "    print(f'{idx}. {transform}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8: Variance of Training Set Features\n",
    "We calculate the variance of the features in the training set. Variance gives an idea of how much the data varies for each feature. This can help identify features that may need normalization or transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recency (months)              58.042\n",
      "Frequency (times)             34.472\n",
      "Monetary (c.c. blood)    2154477.271\n",
      "Time (months)                580.339\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Display variance of the training set\n",
    "print(X_train.var().round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 9: Normalize 'Monetary (c.c. blood)' Feature\n",
    "We apply log transformation to the 'Monetary (c.c. blood)' feature to normalize its distribution. This helps in reducing the effect of extreme values or skewness, improving model performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recency (months)      58.042\n",
      "Frequency (times)     34.472\n",
      "Time (months)        580.339\n",
      "monetary_log           0.826\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Normalize the 'Monetary (c.c. blood)' column using log transformation\n",
    "X_train_normed, X_test_normed = X_train.copy(), X_test.copy()\n",
    "col_to_normalize = 'Monetary (c.c. blood)'\n",
    "for df_ in [X_train_normed, X_test_normed]:\n",
    "    df_['monetary_log'] = np.log(df_[col_to_normalize])\n",
    "    df_.drop(columns=col_to_normalize, inplace=True)\n",
    "print(X_train_normed.var().round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 10: Logistic Regression Model\n",
    "We train a Logistic Regression model on the normalized dataset to predict blood donation. Logistic Regression is a simple yet effective model for binary classification. We evaluate its performance using the AUC score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC score: 0.7691\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(\n",
    "    solver='liblinear',\n",
    "    random_state=42\n",
    ")\n",
    "logreg.fit(X_train_normed, y_train)\n",
    "logreg_auc_score = roc_auc_score(y_test, logreg.predict_proba(X_test_normed)[:, 1])\n",
    "print(f'\\nAUC score: {logreg_auc_score:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 11: Model Comparison\n",
    "We compare the AUC scores of the models generated by TPOT and the manually implemented Logistic Regression model. This comparison helps us understand which approach provided a better predictive performance for this dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tpot', 0.7744883040935673), ('logreg', 0.7691276803118908)]\n"
     ]
    }
   ],
   "source": [
    "# Compare TPOT and Logistic Regression AUC scores\n",
    "from operator import itemgetter\n",
    "model_scores = sorted(\n",
    "    [('tpot', tpot_auc_score), ('logreg', logreg_auc_score)],\n",
    "    key=itemgetter(1),\n",
    "    reverse=True\n",
    ")\n",
    "print(model_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and Significance:\n",
    "The analysis involves predicting blood donations using a dataset of previous donation behavior. We used TPOT, an automated machine learning tool, to select the best model and compared it with a manually implemented Logistic Regression model. The TPOT classifier selected a Logistic Regression model with an AUC score of 0.7304, while our manual Logistic Regression model achieved an AUC score of 0.7384.\n",
    "\n",
    "- TPOT Model AUC Score: 0.7304\n",
    "- Manual Logistic Regression Model AUC Score: 0.7384\n",
    "\n",
    "These results show that both models are relatively close in performance, with the manual logistic regression model performing slightly better. The AUC scores indicate the model's ability to differentiate between classes, with higher scores representing better performance. In this context, both models provide a reasonable ability to predict future blood donations.\n",
    "\n",
    "Accurate forecasting of blood supply is crucial for ensuring that sufficient blood is available when needed, particularly during busy periods like holidays when donation rates may fluctuate. Therefore, implementing these models can help in making informed decisions about blood donation drives and inventory management."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
